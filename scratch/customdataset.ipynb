{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c196661c-50e1-4c69-8424-695d717433e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 02:13:07.382428: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-18 02:13:07.615522: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739812387.707831  109304 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739812387.734496  109304 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 02:13:07.958682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import itertools\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "from contextlib import nullcontext\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import DistributedDataParallelKwargs, ProjectConfiguration, set_seed\n",
    "from huggingface_hub import create_repo, upload_folder\n",
    "from huggingface_hub.utils import insecure_hashlib\n",
    "from peft import LoraConfig, set_peft_model_state_dict\n",
    "from peft.utils import get_peft_model_state_dict\n",
    "from PIL import Image, ImageDraw\n",
    "from PIL.ImageOps import exif_transpose\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import crop\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import CLIPTokenizer, PretrainedConfig, T5TokenizerFast\n",
    "\n",
    "import diffusers\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    FlowMatchEulerDiscreteScheduler,\n",
    "    FluxFillPipeline,\n",
    "    FluxTransformer2DModel,\n",
    ")\n",
    "from diffusers.utils import load_image\n",
    "from diffusers.optimization import get_scheduler\n",
    "from diffusers.training_utils import (\n",
    "    _set_state_dict_into_text_encoder,\n",
    "    cast_training_params,\n",
    "    compute_density_for_timestep_sampling,\n",
    "    compute_loss_weighting_for_sd3,\n",
    "    free_memory,\n",
    ")\n",
    "from diffusers.utils import (\n",
    "    check_min_version,\n",
    "    convert_unet_state_dict_to_peft,\n",
    "    is_wandb_available,\n",
    ")\n",
    "from diffusers.utils.hub_utils import load_or_create_model_card, populate_model_card\n",
    "from diffusers.utils.torch_utils import is_compiled_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16a9969-b0f6-4980-a126-3ee014985e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_data_root = Path(\"./sks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d5145d-8556-4b8f-bf6d-9f3e50ef2fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [path for path in list(Path(instance_data_root).iterdir())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee492ac4-7c18-4b33-8264-87a7ef2551ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('sks/005.jpg'),\n",
       " PosixPath('sks/001.jpg'),\n",
       " PosixPath('sks/004.jpg'),\n",
       " PosixPath('sks/001.txt'),\n",
       " PosixPath('sks/002.jpg'),\n",
       " PosixPath('sks/001_mask.png'),\n",
       " PosixPath('sks/002.txt'),\n",
       " PosixPath('sks/003.jpg'),\n",
       " PosixPath('sks/003_mask.png')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7a4b5a9-9b64-420a-bcaa-071f36c79a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_mask = {}\n",
    "name_to_image = {}\n",
    "name_to_prompt = {}\n",
    "\n",
    "mask_postfix = \"_mask\"\n",
    "\n",
    "for path in sorted(paths):\n",
    "    file_name_with_ext = path.name\n",
    "    file_name, ext = os.path.splitext(file_name_with_ext)\n",
    "    if file_name.lower().endswith(mask_postfix):\n",
    "        name_to_mask[file_name[:-len(mask_postfix)]] = path\n",
    "    elif ext.lower() == \".txt\":\n",
    "        name_to_prompt[file_name] = path\n",
    "    else:\n",
    "        name_to_image[file_name] = path\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ea4bffb-78a4-4a98-9855-f83a54210033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'001': PosixPath('sks/001_mask.png'), '003': PosixPath('sks/003_mask.png')}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19eaa5c1-7a3d-4540-98bc-d919494649d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'001': PosixPath('sks/001.jpg'),\n",
       " '002': PosixPath('sks/002.jpg'),\n",
       " '003': PosixPath('sks/003.jpg'),\n",
       " '004': PosixPath('sks/004.jpg'),\n",
       " '005': PosixPath('sks/005.jpg')}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fccc9767-513a-4ace-a467-bf8d95abee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'001': PosixPath('sks/001.txt'), '002': PosixPath('sks/002.txt')}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5389779-2b2f-4461-85bf-ad243bf1083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_mask(size):\n",
    "    mask = Image.new(\"L\", size, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.rectangle((0, 0, size[0], size[1]), fill=255)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "220fae65-9d2b-49fc-a26a-aa71ad6253ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_prompt = \"a sks dog\"\n",
    "instance_images = []\n",
    "pil_images = []\n",
    "mask_images = []\n",
    "custom_instance_prompts = []\n",
    "pixel_values = []\n",
    "\n",
    "for name in sorted(name_to_image):\n",
    "    try:\n",
    "        instance_image = Image.open(name_to_image[name])\n",
    "        instance_images.append(instance_image)\n",
    "        \n",
    "        if name in name_to_mask:\n",
    "            mask_image = Image.open(name_to_mask[name])\n",
    "            mask_images.append(mask_image)\n",
    "        else:\n",
    "            mask_image = generate_full_mask(instance_image.size)\n",
    "            mask_images.append(mask_image)\n",
    "            \n",
    "        if name in name_to_prompt:\n",
    "            with open(name_to_prompt[name], \"r\") as prompt_file:\n",
    "                prompt_text = prompt_file.read()\n",
    "                custom_instance_prompts.append(prompt_text)\n",
    "        else:\n",
    "            custom_instance_prompts.append(instance_prompt)\n",
    "    except (IOError, AttributeError) as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36c8eaa4-bd5e-49bc-91a2-6c1e5d41c6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1815x1967>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2469x2558>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2796x2656>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2476x2612>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=2732x2736>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8949a08d-836d-406c-bf9e-000ca0d07494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1815x1967>,\n",
       " <PIL.Image.Image image mode=L size=2469x2558>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=2796x2656>,\n",
       " <PIL.Image.Image image mode=L size=2476x2612>,\n",
       " <PIL.Image.Image image mode=L size=2732x2736>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8018320-a4aa-4d74-bb14-3f240e2fa26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sks dog,tongue',\n",
       " 'sks dog licking his lip',\n",
       " 'a sks dog',\n",
       " 'a sks dog',\n",
       " 'a sks dog']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_instance_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cacd0da8-4fd4-4ea7-8482-a4f350df21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1024\n",
    "center_crop = False\n",
    "train_resize = transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "train_crop = transforms.CenterCrop(size) if center_crop else transforms.RandomCrop(size)\n",
    "train_flip = transforms.RandomHorizontalFlip(p=1.0)\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb610652-7511-4414-ae55-13bd12a7ac94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_flip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m train_resize(image)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrandom_flip\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# flip\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     image \u001b[38;5;241m=\u001b[39m train_flip(image)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m center_crop:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_flip' is not defined"
     ]
    }
   ],
   "source": [
    "pil_images = []\n",
    "for image in instance_images:\n",
    "    image = exif_transpose(image)\n",
    "    if not image.mode == \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    image = train_resize(image)\n",
    "\n",
    "\n",
    "    else:\n",
    "        y1, x1, h, w = train_crop.get_params(image, (args.resolution, args.resolution))\n",
    "        image = crop(image, y1, x1, h, w)\n",
    "    pil_images.append(image.copy())\n",
    "    image = train_transforms(image)\n",
    "    pixel_values.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dced9d69-54bd-4d19-8e18-bc77064172b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mask_and_masked_image(image, mask):\n",
    "    image = np.array(image.convert(\"RGB\"))\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image).to(dtype=torch.float32) / 127.5 - 1.0\n",
    "\n",
    "    mask = np.array(mask.convert(\"L\"))\n",
    "    mask = mask.astype(np.float32) / 255.0\n",
    "    mask = mask[None, None]\n",
    "    mask[mask < 0.5] = 0\n",
    "    mask[mask >= 0.5] = 1\n",
    "    mask = torch.from_numpy(mask)\n",
    "\n",
    "    masked_image = image * (mask < 0.5)\n",
    "    \n",
    "    return mask, masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3de2f5f-6103-4f07-9165-a5de9fd7bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_new = train_resize(instance_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff314e31-af86-4535-b438-c274c6896062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1109)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_new.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5f2c6e40-292b-4a5c-9067-86c1aa44c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, masked_image = prepare_mask_and_masked_image(instance_images[0], mask_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8e287e4d-98bd-45c6-aa85-8f942e5420ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1967, 1815])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "adfb68f6-8490-459c-a0ac-6bb01f864de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1967, 1815])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4f913151-97cc-4bec-8c4e-54e135094fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = masked_image.numpy()\n",
    "masked_image = masked_image[0].transpose(1, 2, 0)\n",
    "masked_image = (masked_image + 1.0) * 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2f20a438-3bc9-4056-9a12-d02fee9455e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = np.clip(masked_image, 0, 255).astype(np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d5075216-bbc9-41a4-8963-d0a8c3019bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.fromarray(masked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ee7b4a22-b533-44e5-9072-157dc863bf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1967, 1815])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b5a09-4941-4826-b892-13876cf8651e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
